---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am Yuanhao LiuÔºàÂàòÂÖÉÊµ©Ôºâ, a Ph.D. candidate at the Institute of Computing Technology, Chinese Academy of Sciences, affiliated with the National Key Laboratory of Intelligent Algorithm Security, under the supervision of Prof. Huawei ShenÔºàÊ≤àÂçé‰ºüÔºâ. I received my B.Eng. degree in Software Engineering from the School of Software, Nankai University, in 2020.

My research investigates algorithmic fairness, with the aim of developing technologies that are fair, trustworthy, and socially responsible. Please feel free to email me at <a href='liuyuanhao.cn@gmail.com'>liuyuanhao.cn@gmail.com</a> for any form of academic communication or collaboration.

I have published papers at the top international AI conferences such as WWW, SIGIR, CSCW.


# üî• News
- *2025.10*: &nbsp;üéâ Paper accepted to ACM CSCW 2025.

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CSCW 2025</div><img src='images/cscw2025substantiating.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

["I Know You Are Discriminatory!": Automated Substantiating for Individual Fairness Auditing of AI Systems](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

**Yuanhao Liu**, Qi Cao, Huawei Shen, Kaike Zhang, Yunfan Wu, Xueqi Cheng

[**Code**]()
- Designed auditing techniques to evaluate individual fairness in AI systems when access to model internals and training data is restricted, and developed substantiating frameworks for fairness violations.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">The Innovation</div><img src='images/innovation2025safety.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[The rising safety concerns of deep recommender systems](https://www.sciencedirect.com/science/article/pii/S2666675825002413)

Huawei Shen, **Yuanhao Liu**, Kaike Zhang, Qi Cao, Xueqi Cheng

[**Code**](https://github.com/UnitDan/IPL)
- Redefined fairness on the item side of recommendations from the perspective of click volume. The method achieved a win‚Äìwin between recommendation accuracy and fairness.
- Recognized by the [WSDM 2025 Best Paper](https://dl.acm.org/doi/abs/10.1145/3701551.3703579) as a representative approach for popularity debiasing.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">SIGIR 2023</div><img src='images/sigir2023IPL.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Popularity debiasing from exposure to interaction in collaborative filtering](https://dl.acm.org/doi/abs/10.1145/3539618.3591947)

**Yuanhao Liu**, Qi Cao, Huawei Shen, Yunfan Wu, Shuchang Tao, Xueqi Cheng

[**Code**](https://github.com/UnitDan/IPL)
- Redefined fairness on the item side of recommendations from the perspective of click volume. The method achieved a win‚Äìwin between recommendation accuracy and fairness.
- Recognized by the [WSDM 2025 Best Paper](https://dl.acm.org/doi/abs/10.1145/3701551.3703579) as a representative approach for popularity debiasing.
</div>
</div>

- [PREP: Pre-training with temporal elapse inference for popularity prediction](https://dl.acm.org/doi/abs/10.1145/3487553.3524249), Qi Cao, Huawei Shen, **Yuanhao Liu**, Jinhua Gao, Xueqi Cheng, **WWW 2022**

# üéñ Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üìñ Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# üíª Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.
