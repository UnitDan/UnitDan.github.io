---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am Yuanhao Liuï¼ˆåˆ˜å…ƒæµ©ï¼‰, a Ph.D. candidate at the Institute of Computing Technology, Chinese Academy of Sciences, affiliated with the National Key Laboratory of Intelligent Algorithm Security, under the supervision of Prof. Huawei Shenï¼ˆæ²ˆåä¼Ÿï¼‰. I received my B.Eng. degree in Software Engineering from the School of Software, Nankai University, in 2020.

My research investigates algorithmic fairness, with the aim of developing technologies that are fair, trustworthy, and socially responsible. Please feel free to email me at <a href='liuyuanhao.cn@gmail.com'>liuyuanhao.cn@gmail.com</a> for any form of academic communication or collaboration.

I have published papers at the top international AI conferences such as WWW, SIGIR, CSCW.


# ğŸ”¥ News
- *2025.10*: &nbsp;ğŸ‰ Paper accepted to ACM CSCW 2025.

# ğŸ“ Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CSCW 2025</div><img src='images/cscw2025substantiating.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

["I Know You Are Discriminatory!": Automated Substantiating for Individual Fairness Auditing of AI Systems](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

**Yuanhao Liu**, Qi Cao, Huawei Shen, Kaike Zhang, Yunfan Wu, Xueqi Cheng

[**Code**]()
- Designed auditing techniques to evaluate individual fairness in AI systems when access to model internals and training data is restricted, and developed substantiating frameworks for fairness violations.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">The Innovation</div><img src='images/innovation2025safety.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[The rising safety concerns of deep recommender systems](https://www.sciencedirect.com/science/article/pii/S2666675825002413)

Huawei Shen, **Yuanhao Liu**, Kaike Zhang, Qi Cao, Xueqi Cheng

- Reviewed the development of recommender systems and the accompanying security issues, particularly fairness, robustness, and filter bubble problems, and outlined future research directions.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">SIGIR 2023</div><img src='images/sigir2023IPL.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Popularity debiasing from exposure to interaction in collaborative filtering](https://dl.acm.org/doi/abs/10.1145/3539618.3591947)

**Yuanhao Liu**, Qi Cao, Huawei Shen, Yunfan Wu, Shuchang Tao, Xueqi Cheng

[**Code**](https://github.com/UnitDan/IPL)
- Redefined fairness on the item side of recommendations from the perspective of click volume. The method achieved a winâ€“win between recommendation accuracy and fairness.
- Recognized by the [WSDM 2025 Best Paper](https://dl.acm.org/doi/abs/10.1145/3701551.3703579) as a representative approach for popularity debiasing.
</div>
</div>

- [PREP: Pre-training with temporal elapse inference for popularity prediction](https://dl.acm.org/doi/abs/10.1145/3487553.3524249), Qi Cao, Huawei Shen, **Yuanhao Liu**, Jinhua Gao, Xueqi Cheng, **WWW 2022**

# ğŸ– Honors and Awards
- *2024.03* Excellent Student Award from the Institute of Computing Technology, Chinese Academy of Sciences. 

# ğŸ“– Educations
- *2020.09 - (now)*, Ph.D. Candidate, Institute of Computing Technology, Chinese Academy of Sciences.
- *2016.09 - 2020.07*, B.Eng., School of Software, Nankai University.

# ğŸ’¬ Invited Talks
- *2025.10*, CSCW 2025, Bergen, Norway.
- *2023.07*, SIGIR 2023, online. 
- *2023.06*, AIS 2023, Changsha, China.

# ğŸ’» Internships
